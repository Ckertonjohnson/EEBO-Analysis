# main.ipynb
from google.colab import drive
drive.mount('/content/drive')

!pip install pandas

import os
import pandas as pd
from xml.etree import ElementTree as ET
import nltk
from nltk.corpus import stopwords
import spacy
from lxml import etree as ET
import json
import csv
from concurrent.futures import ThreadPoolExecutor

# Initialize spacy 'en' model, keeping only tagger component needed for lemmatization and disables other tools, to save resources.
nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])
nlp.max_length = 70000000  # Adjust as needed

# Download NLTK stopwords list
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
